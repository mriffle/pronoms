{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronoms: Proteomics Normalization Examples\n",
    "\n",
    "This notebook demonstrates the usage of the Pronoms library for normalizing proteomics data using various methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and create some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Import normalizers from pronoms\n",
    "from pronoms.normalizers import (\n",
    "    MedianNormalizer,\n",
    "    QuantileNormalizer,\n",
    "    L1Normalizer,\n",
    "    DirectLFQNormalizer,\n",
    "    VSNNormalizer\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "Let's create a synthetic proteomics dataset with systematic biases to demonstrate normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data(n_proteins=1000, n_samples=6, bias_factors=None):\n",
    "    \"\"\"\n",
    "    Generate synthetic proteomics data with systematic biases.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_proteins : int, optional\n",
    "        Number of proteins, by default 1000\n",
    "    n_samples : int, optional\n",
    "        Number of samples, by default 6\n",
    "    bias_factors : list, optional\n",
    "        Bias factors for each sample, by default None\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Synthetic proteomics data with shape (n_proteins, n_samples)\n",
    "    \"\"\"\n",
    "    # Generate base protein abundances (log-normal distribution)\n",
    "    protein_means = np.random.normal(10, 2, n_proteins)\n",
    "    protein_stds = np.random.uniform(0.1, 0.5, n_proteins)\n",
    "    \n",
    "    # Generate data matrix\n",
    "    data = np.zeros((n_proteins, n_samples))\n",
    "    for i in range(n_proteins):\n",
    "        data[i, :] = np.random.normal(protein_means[i], protein_stds[i], n_samples)\n",
    "    \n",
    "    # Add systematic biases if provided\n",
    "    if bias_factors is not None:\n",
    "        for j, factor in enumerate(bias_factors):\n",
    "            data[:, j] *= factor\n",
    "    \n",
    "    # Exponentiate to get raw intensities\n",
    "    data = np.exp(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate data with systematic biases\n",
    "bias_factors = [0.7, 1.0, 1.3, 0.8, 1.2, 0.9]  # Systematic biases for each sample\n",
    "data = generate_sample_data(bias_factors=bias_factors)\n",
    "\n",
    "# Create sample names\n",
    "sample_names = [f\"Sample {i+1}\" for i in range(data.shape[1])]\n",
    "\n",
    "# Display data shape\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Sample names: {sample_names}\")\n",
    "\n",
    "# Show summary statistics\n",
    "df = pd.DataFrame(data, columns=sample_names)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Raw Data\n",
    "\n",
    "Let's visualize the raw data to see the systematic biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(data, labels=sample_names)\n",
    "plt.title(\"Raw Data Distribution\")\n",
    "plt.ylabel(\"Intensity\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also show on log scale\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(np.log2(data), labels=sample_names)\n",
    "plt.title(\"Log2 Raw Data Distribution\")\n",
    "plt.ylabel(\"Log2 Intensity\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Median Normalization\n",
    "\n",
    "Median normalization scales each sample by its median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and apply median normalizer\n",
    "median_normalizer = MedianNormalizer()\n",
    "median_normalized_data = median_normalizer.normalize(data)\n",
    "\n",
    "# Plot comparison\n",
    "median_normalizer.plot_comparison(data, median_normalized_data, sample_names=sample_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantile Normalization\n",
    "\n",
    "Quantile normalization makes the distribution of intensities identical across all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and apply quantile normalizer\n",
    "quantile_normalizer = QuantileNormalizer()\n",
    "quantile_normalized_data = quantile_normalizer.normalize(data)\n",
    "\n",
    "# Plot comparison\n",
    "fig, fig2 = quantile_normalizer.plot_comparison(data, quantile_normalized_data, sample_names=sample_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. L1 Normalization\n",
    "\n",
    "L1 normalization scales each sample to have a sum of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and apply L1 normalizer\n",
    "l1_normalizer = L1Normalizer()\n",
    "l1_normalized_data = l1_normalizer.normalize(data)\n",
    "\n",
    "# Plot comparison\n",
    "l1_normalizer.plot_comparison(data, l1_normalized_data, sample_names=sample_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DirectLFQ Normalization (R-based)\n",
    "\n",
    "DirectLFQ is a label-free quantification method implemented in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create and apply DirectLFQ normalizer\n",
    "    directlfq_normalizer = DirectLFQNormalizer(impute_missing=True)\n",
    "    directlfq_normalized_data = directlfq_normalizer.normalize(data, sample_ids=sample_names)\n",
    "    \n",
    "    # Plot comparison\n",
    "    directlfq_normalizer.plot_comparison(data, directlfq_normalized_data, sample_names=sample_names)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"DirectLFQ normalization failed: {str(e)}\")\n",
    "    print(\"This is likely because the R package 'DirectLFQ' is not installed.\")\n",
    "    print(\"To install it, run the following in R:\")\n",
    "    print(\"if (!require(\\\"BiocManager\\\", quietly = TRUE)) install.packages(\\\"BiocManager\\\")\")\n",
    "    print(\"BiocManager::install(\\\"DirectLFQ\\\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VSN Normalization (R-based)\n",
    "\n",
    "Variance Stabilizing Normalization (VSN) stabilizes the variance across the intensity range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create and apply VSN normalizer\n",
    "    vsn_normalizer = VSNNormalizer()\n",
    "    vsn_normalized_data = vsn_normalizer.normalize(data, sample_ids=sample_names)\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, fig2 = vsn_normalizer.plot_comparison(data, vsn_normalized_data, sample_names=sample_names)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"VSN normalization failed: {str(e)}\")\n",
    "    print(\"This is likely because the R package 'vsn' is not installed.\")\n",
    "    print(\"To install it, run the following in R:\")\n",
    "    print(\"if (!require(\\\"BiocManager\\\", quietly = TRUE)) install.packages(\\\"BiocManager\\\")\")\n",
    "    print(\"BiocManager::install(\\\"vsn\\\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of All Methods\n",
    "\n",
    "Let's compare all normalization methods side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot boxplots of all methods\n",
    "def plot_all_methods(raw_data, normalized_data_dict, sample_names=None):\n",
    "    n_methods = len(normalized_data_dict) + 1  # +1 for raw data\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = GridSpec(2, 3, figure=fig)\n",
    "    \n",
    "    # Plot raw data\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.boxplot(raw_data, labels=sample_names)\n",
    "    ax1.set_title(\"Raw Data\")\n",
    "    ax1.set_ylabel(\"Intensity\")\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot normalized data for each method\n",
    "    positions = [(0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "    for i, (method_name, norm_data) in enumerate(normalized_data_dict.items()):\n",
    "        if i < len(positions):\n",
    "            ax = fig.add_subplot(gs[positions[i]])\n",
    "            ax.boxplot(norm_data, labels=sample_names)\n",
    "            ax.set_title(f\"{method_name} Normalized\")\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            if positions[i][1] == 0:\n",
    "                ax.set_ylabel(\"Intensity\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create a dictionary of normalized data\n",
    "normalized_data = {\n",
    "    \"Median\": median_normalized_data,\n",
    "    \"Quantile\": quantile_normalized_data,\n",
    "    \"L1\": l1_normalized_data\n",
    "}\n",
    "\n",
    "# Add R-based methods if available\n",
    "try:\n",
    "    normalized_data[\"DirectLFQ\"] = directlfq_normalized_data\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    normalized_data[\"VSN\"] = vsn_normalized_data\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Plot all methods\n",
    "plot_all_methods(data, normalized_data, sample_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated the use of various normalization methods provided by the Pronoms library:\n",
    "\n",
    "1. **Median Normalization**: Simple and effective for correcting systematic biases.\n",
    "2. **Quantile Normalization**: Makes the distributions identical across samples.\n",
    "3. **L1 Normalization**: Scales each sample to have a sum of 1.\n",
    "4. **DirectLFQ Normalization**: A label-free quantification method that includes normalization (R-based).\n",
    "5. **VSN Normalization**: Stabilizes variance across the intensity range (R-based).\n",
    "\n",
    "Each method has its strengths and is suitable for different types of proteomics data and analysis goals. The choice of normalization method should be based on the specific characteristics of your data and the assumptions of your downstream analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
